{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langsmith-academy\"\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing with @traceable  \n",
    "`@traceable` デコレーターは、LangSmith Python SDKからトレースをログに記録するためのシンプルな方法です。任意の関数に`@traceable`をデコレーターとして付けるだけで利用できます。\n",
    "\n",
    "このデコレーターは、関数が呼び出されるたびにランツリー（run tree）を作成し、現在のトレース内に挿入する仕組みです。関数の入力、名前、その他の情報がLangSmithにストリームとして送信されます。関数がエラーを発生させた場合やレスポンスを返した場合、その情報もツリーに追加され、LangSmithにパッチ更新されます。そのため、エラーの原因を特定し、診断することが可能になります。これらはすべてバックグラウンドスレッドで実行されるため、アプリケーションの実行がブロックされることはありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question:str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "def generate_answer(question:str, documents:List[str]):\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
